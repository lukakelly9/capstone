{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1YS8FCWWwOq"
   },
   "source": [
    "# Modeling:\n",
    "\n",
    "### CNN Model - 10 Epochs with Early Stopping, no Data Augmentation\n",
    "__________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ium5DAYMW5bV"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-xHhzTTt9yqw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1AmYdDfBmDgq",
    "outputId": "554c3c2b-969a-4def-996d-26c8d2d0248b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting my drive\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gk_gNj6bmGi_"
   },
   "outputs": [],
   "source": [
    "# assigning proper file path to training data\n",
    "\n",
    "training_data_dir = \"/content/drive/MyDrive/GA Data Science Bootcamp/Projects/Capstone Project/Facial Recognition Data/Training/Training/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzEjVD0KmONp",
    "outputId": "cd4ccbbe-50fd-449e-d947-b73ffc3d4ff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Renaming file names in training data due to a \"FileNotFoundError\" I kept getting when trying to run my models\n",
    "\n",
    "# Setting the directory path where the files are located\n",
    "training_directory_path = training_data_dir\n",
    "\n",
    "# Initialize a starting index\n",
    "start_index = 1\n",
    "\n",
    "# Iterating over the files in the directory\n",
    "for filename in os.listdir(training_directory_path):\n",
    "    # Checking if the item is a file\n",
    "    if os.path.isfile(os.path.join(training_directory_path, filename)):\n",
    "        # Getting the file extension\n",
    "        file_extension = os.path.splitext(filename)[1]\n",
    "\n",
    "        # Defining the new filename with the updated index\n",
    "        new_filename = f\"{start_index}{file_extension}\"\n",
    "\n",
    "        # Building the full path for the old and new filenames\n",
    "        old_filepath = os.path.join(training_directory_path, filename)\n",
    "        new_filepath = os.path.join(training_directory_path, new_filename)\n",
    "\n",
    "        # Renaming the file\n",
    "        os.rename(old_filepath, new_filepath)\n",
    "\n",
    "        # Incrementing the index\n",
    "        start_index += 1\n",
    "\n",
    "print(\"Files renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXPVC0UHmlgp",
    "outputId": "ccf543b3-67e0-4163-8719-59437a98b078"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28303 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating an instance of ImageDataGenerator for preprocessing of image data, and rescaling the pixel values to be in the range of 0.0-1.0.\n",
    "\n",
    "training_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_data_generator = training_datagen.flow_from_directory( # configuring the data generator to read, preprocess, and prepare the images for training\n",
    "        training_directory_path,\n",
    "        target_size=(224, 224), # resizing the input images to a target size of 224 x 224\n",
    "        batch_size=32, # specifying data loading in batches of 32 samples at a time, helping memory efficiency during training\n",
    "        class_mode='categorical') # specifying that the dataset contains multiple categorical classes, rather than just two (binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eWJFRSbPnmUD"
   },
   "outputs": [],
   "source": [
    "# assigning proper file path to testing data\n",
    "\n",
    "testing_data_dir = '/content/drive/MyDrive/GA Data Science Bootcamp/Projects/Capstone Project/Facial Recognition Data/Testing/Testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ri-HENXwnoXP",
    "outputId": "adcb37af-6fde-4f2f-b776-e1263970a328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing files renamed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Doing the same to the testing data as above to the training data\n",
    "\n",
    "testing_directory_path = testing_data_dir\n",
    "\n",
    "start_index = 1\n",
    "\n",
    "for filename in os.listdir(testing_directory_path):\n",
    "    if os.path.isfile(os.path.join(testing_directory_path, filename)):\n",
    "        file_extension = os.path.splitext(filename)[1]\n",
    "\n",
    "        new_filename = f\"{start_index}{file_extension}\"\n",
    "\n",
    "        old_filepath = os.path.join(testing_directory_path, filename)\n",
    "        new_filepath = os.path.join(testing_directory_path, new_filename)\n",
    "\n",
    "        os.rename(old_filepath, new_filepath)\n",
    "\n",
    "        start_index += 1\n",
    "\n",
    "print(\"Testing files renamed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWOv104uoDYA",
    "outputId": "e310a0b5-bf6c-4c16-f0f1-acc23480b134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7067 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# see \"training_datagen\" comments\n",
    "\n",
    "testing_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "testing_data_generator = testing_datagen.flow_from_directory(\n",
    "        testing_directory_path,\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbu417iLVizZ"
   },
   "source": [
    "_________________________\n",
    "## CNN with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2mpU3w7joNCX"
   },
   "outputs": [],
   "source": [
    "early_stopping_model = Sequential()\n",
    "\n",
    "early_stopping_model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 3)))\n",
    "early_stopping_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "early_stopping_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "early_stopping_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "early_stopping_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "early_stopping_model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "early_stopping_model.add(Flatten())\n",
    "early_stopping_model.add(Dense(128, activation='relu'))\n",
    "early_stopping_model.add(Dropout(0.5))\n",
    "\n",
    "early_stopping_model.add(Dense(6, activation='softmax'))  # 6 classes for emotions\n",
    "\n",
    "# Compile the model\n",
    "early_stopping_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "swmF2KQyobUH"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBFBY-XAodkP",
    "outputId": "2d346a25-1166-42ba-c8a5-699210856f4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "885/885 [==============================] - 9198s 10s/step - loss: 1.6694 - accuracy: 0.3119 - val_loss: 1.4797 - val_accuracy: 0.4111\n",
      "Epoch 2/10\n",
      "885/885 [==============================] - 2968s 3s/step - loss: 1.4527 - accuracy: 0.4255 - val_loss: 1.3403 - val_accuracy: 0.4663\n",
      "Epoch 3/10\n",
      "885/885 [==============================] - 3022s 3s/step - loss: 1.3091 - accuracy: 0.4859 - val_loss: 1.3446 - val_accuracy: 0.4796\n",
      "Epoch 4/10\n",
      "885/885 [==============================] - 3004s 3s/step - loss: 1.1840 - accuracy: 0.5447 - val_loss: 1.3064 - val_accuracy: 0.4996\n",
      "Epoch 5/10\n",
      "885/885 [==============================] - 3014s 3s/step - loss: 1.0387 - accuracy: 0.6019 - val_loss: 1.3156 - val_accuracy: 0.5013\n",
      "Epoch 6/10\n",
      "885/885 [==============================] - 3029s 3s/step - loss: 0.9114 - accuracy: 0.6555 - val_loss: 1.4048 - val_accuracy: 0.5057\n",
      "Epoch 7/10\n",
      "885/885 [==============================] - 3010s 3s/step - loss: 0.7899 - accuracy: 0.6964 - val_loss: 1.4375 - val_accuracy: 0.5056\n"
     ]
    }
   ],
   "source": [
    "# Training the model with early stopping for 10 epochs\n",
    "try:\n",
    "    history = early_stopping_model.fit(\n",
    "        training_data_generator,\n",
    "        steps_per_epoch=len(training_data_generator),\n",
    "        epochs=10,\n",
    "        validation_data=testing_data_generator,\n",
    "        validation_steps=len(testing_data_generator),\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FileNotFoundError: {e}\")\n",
    "    print(\"Skipping this step due to missing files in the dataset.\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut5FTEtj_o36"
   },
   "source": [
    "As we can see above, adding in more epochs to the model improved its training accuracy(~0.70 after 7 epochs, vs ~0.61 after 5 epochs in my previous model), but the testing accuracy begins to stagnate around 0.5. Additionally, the model becomes increasingly overfit as it move higher in the number of epochs, stopping at epoch 7 due to the early stopping clause specifying to stop running the model if the validation loss increased for three epochs straight(which it did, from epoch 5 to 7)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
